{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG-16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9ndq3V4HOHdbTZOeiWO55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivdutta/AdvanceCNN/blob/master/VGG_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TdxvD0V0y7d",
        "colab_type": "code",
        "outputId": "9ce39473-d05e-4916-8cb0-4aef6f197abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "!unzip -q \"/content/gdrive/My Drive/CNN_Images/ImagesPred.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug27Nh1P1PSr",
        "colab_type": "code",
        "outputId": "58af7bb6-8e83-470c-e0c8-e18c28588a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls /content/ImagesPred/Images/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mTest\u001b[0m/  \u001b[01;34mTrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAtlw4Kb7E-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras import optimizers \n",
        "from keras.callbacks import TensorBoard,ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "from time import time\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izUfDiWLGW1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rte3Gma7OZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Give dataset path\n",
        "trainpath = \"/content/ImagesPred/Images/Train\"\n",
        "testpath = \"/content/ImagesPred/Images/Test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCPH4kQOGXnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3OJw34F8gg0",
        "colab_type": "code",
        "outputId": "5bc35757-d56b-439a-8f68-8b1a4bfd0d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "batch_size=16\n",
        "Image_Size =32\n",
        "  \n",
        "train_datagen = image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        " \n",
        "test_datagen = image.ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        trainpath,\n",
        "        target_size=(Image_Size, Image_Size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        testpath,\n",
        "        target_size=(Image_Size,Image_Size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 32 images belonging to 4 classes.\n",
            "Found 8 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtvMzXtZGYZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnLzB1mh8hYY",
        "colab_type": "code",
        "outputId": "cb20f64e-a447-45ed-fae4-aaa479895cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from keras import applications\n",
        "\n",
        "# This will load the whole VGG16 network, including the top Dense layers.\n",
        "# Note: by specifying the shape of top layers, input tensor shape is forced\n",
        "# to be (224, 224, 3), therefore you can use it only on 224x224 images.\n",
        "#vgg_model = applications.VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "# If you are only interested in convolution filters. Note that by not\n",
        "# specifying the shape of top layers, the input tensor shape is (None, None, 3),\n",
        "# so you can use them for any size of images.\n",
        "#vgg_model = applications.VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# If you want to specify input tensor\n",
        "from keras.layers import Input\n",
        "input_tensor = Input(shape=(Image_Size, Image_Size, 3))\n",
        "vgg_model = applications.VGG16(weights='imagenet',\n",
        "                               include_top=False,\n",
        "                               input_tensor=input_tensor)\n",
        "\n",
        "# To see the models' architecture and layer names, run the following\n",
        "#vgg_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg9eKpvTGZI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bcDGU2kKj8b",
        "colab_type": "code",
        "outputId": "d3d6629b-1ba9-4dd5-d695-c302293856a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# Creating dictionary that maps layer names to the layers\n",
        "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
        "\n",
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'block1_conv1': <keras.layers.convolutional.Conv2D at 0x7f046e8f25f8>,\n",
              " 'block1_conv2': <keras.layers.convolutional.Conv2D at 0x7f042c16ce80>,\n",
              " 'block1_pool': <keras.layers.pooling.MaxPooling2D at 0x7f042c16cba8>,\n",
              " 'block2_conv1': <keras.layers.convolutional.Conv2D at 0x7f042c16c780>,\n",
              " 'block2_conv2': <keras.layers.convolutional.Conv2D at 0x7f04204c7ba8>,\n",
              " 'block2_pool': <keras.layers.pooling.MaxPooling2D at 0x7f04204d2748>,\n",
              " 'block3_conv1': <keras.layers.convolutional.Conv2D at 0x7f04204d2588>,\n",
              " 'block3_conv2': <keras.layers.convolutional.Conv2D at 0x7f04204dc9b0>,\n",
              " 'block3_conv3': <keras.layers.convolutional.Conv2D at 0x7f04204dce10>,\n",
              " 'block3_pool': <keras.layers.pooling.MaxPooling2D at 0x7f04204e4898>,\n",
              " 'block4_conv1': <keras.layers.convolutional.Conv2D at 0x7f04204e46d8>,\n",
              " 'block4_conv2': <keras.layers.convolutional.Conv2D at 0x7f04204ea3c8>,\n",
              " 'block4_conv3': <keras.layers.convolutional.Conv2D at 0x7f04204eada0>,\n",
              " 'block4_pool': <keras.layers.pooling.MaxPooling2D at 0x7f04204ef9e8>,\n",
              " 'block5_conv1': <keras.layers.convolutional.Conv2D at 0x7f04204ef828>,\n",
              " 'block5_conv2': <keras.layers.convolutional.Conv2D at 0x7f04204f6518>,\n",
              " 'block5_conv3': <keras.layers.convolutional.Conv2D at 0x7f04204f6e10>,\n",
              " 'block5_pool': <keras.layers.pooling.MaxPooling2D at 0x7f04204ffb38>,\n",
              " 'input_1': <keras.engine.input_layer.InputLayer at 0x7f046e8f6828>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm2vY-RNXGvs",
        "colab_type": "code",
        "outputId": "be49116d-49d8-422e-9659-5eaabde4b376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Getting output tensor of the last VGG layer that we want to include . It is not block5_pool\n",
        "x = layer_dict['block2_pool'].output\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'block2_pool/MaxPool:0' shape=(None, 8, 8, 128) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9QPmpr7sv1f",
        "colab_type": "code",
        "outputId": "5dfb77fd-ae95-4ae4-c962-3ed9d91f2f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(layer_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZTspGsmWwaE",
        "colab_type": "code",
        "outputId": "e47cee5d-49e2-401f-8d04-3799b86356a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# We are considering upto 7th layer which is x variable\n",
        "# Stacking a new simple convolutional network on top of it    \n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "# x = GlobalAveragePooling2D()(x) #change ndim from 2 to 4\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(4, activation='softmax')(x)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense_2/Softmax:0' shape=(None, 4) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJCa9otyQNY",
        "colab_type": "code",
        "outputId": "cb2fc42a-fdb9-435d-ac54-44d2c8df3877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x.shape,x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([None, 4]),\n",
              " <tf.Tensor 'dense_2/Softmax:0' shape=(None, 4) dtype=float32>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70MXVpNyllXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sch(epoch):\n",
        "  return round(0.004 * 1/(1 + 0.319 * epoch), 10)  \n",
        "\n",
        "\n",
        "decay_rate = []\n",
        "drop = 0.5\n",
        "epochs_drop = 1.0\n",
        "initial_lrate = 0.1\n",
        "\n",
        "def step_decay(epoch):    \n",
        "    # LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop)\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    \n",
        "    # Store the decaying learning rate in a list\n",
        "    decay_rate.append(lrate)\n",
        "    \n",
        "    return lrate\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * math.exp(0.1 * (10 - epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA1icPR9yDOM",
        "colab_type": "code",
        "outputId": "0d4b18a9-0d72-44d0-f332-ce0483fdf8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Creating new model. Please note that this is NOT a Sequential() model.\n",
        "from keras.models import Model\n",
        "custom_model = Model(input=vgg_model.input, output=x)\n",
        "\n",
        "# Make sure that the pre-trained bottom layers are not trainable\n",
        "for layer in custom_model.layers[:6]:\n",
        "    layer.trainable = False\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "layer.output.shape\n",
        "#custom_model.summary()\n",
        "\n",
        "filepath = '/content/gdrive/My Drive/saved models/vgg16_model.h5'\n",
        "checkpoint = ModelCheckpoint  (filepath, monitor='val_loss', verbose=1,save_best_only=True,save_weights_only=False, mode='auto',period=1)\n",
        "\n",
        "#Initialize Learning Rate Scheduler Callback\n",
        "#lr = LearningRateScheduler(sch)\n",
        "#lr = LearningRateScheduler(step_decay)\n",
        "lr = LearningRateScheduler(scheduler)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks_list = [checkpoint,lr]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgNx7xJl2mNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optimizers.Adam()\n",
        "custom_model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMBhZDV_wAfh",
        "colab_type": "code",
        "outputId": "be947637-5e7f-4223-e4f2-ad693cf28639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = custom_model.fit_generator(train_generator,\n",
        "                         steps_per_epoch = len(train_generator),\n",
        "                         epochs = 200,\n",
        "                         validation_data = validation_generator,callbacks=callbacks_list) \n",
        "#validation_steps=len(validation_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 11s 5s/step - loss: 19.2560 - accuracy: 0.2812 - val_loss: 15.4792 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 15.47919, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 17.1216 - accuracy: 0.2500 - val_loss: 4.2528 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00002: val_loss improved from 15.47919 to 4.25282, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 9.3315 - accuracy: 0.5312 - val_loss: 5.2064 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 4.25282\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 9.3850 - accuracy: 0.3125 - val_loss: 2.9578 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00004: val_loss improved from 4.25282 to 2.95783, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 3.5998 - accuracy: 0.6250 - val_loss: 5.1438 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 2.95783\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 3.5744 - accuracy: 0.4375 - val_loss: 4.7415 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 2.95783\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 2.6925 - accuracy: 0.6875 - val_loss: 3.6679 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 2.95783\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 2.6001 - accuracy: 0.5312 - val_loss: 3.3189 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 2.95783\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 1.4396 - accuracy: 0.6562 - val_loss: 3.3122 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 2.95783\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 1.6564 - accuracy: 0.6875 - val_loss: 2.9810 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 2.95783\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 1.2489 - accuracy: 0.6250 - val_loss: 3.2609 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.95783\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 1.4266 - accuracy: 0.6875 - val_loss: 3.5763 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 2.95783\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 1.0910 - accuracy: 0.7188 - val_loss: 3.6616 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.95783\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 1.0710 - accuracy: 0.7188 - val_loss: 3.0268 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.95783\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.7304 - accuracy: 0.8750 - val_loss: 2.7117 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.95783 to 2.71170, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3113 - accuracy: 0.9062 - val_loss: 2.3721 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00016: val_loss improved from 2.71170 to 2.37214, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3667 - accuracy: 0.8750 - val_loss: 2.1776 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00017: val_loss improved from 2.37214 to 2.17764, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3290 - accuracy: 0.9062 - val_loss: 2.1455 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00018: val_loss improved from 2.17764 to 2.14547, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.8053 - accuracy: 0.7812 - val_loss: 2.2041 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 2.14547\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4893 - accuracy: 0.8125 - val_loss: 2.2471 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 2.14547\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.5373 - accuracy: 0.8125 - val_loss: 2.1918 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 2.14547\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3292 - accuracy: 0.8125 - val_loss: 2.1590 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 2.14547\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4924 - accuracy: 0.8125 - val_loss: 2.1119 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00023: val_loss improved from 2.14547 to 2.11186, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3626 - accuracy: 0.8125 - val_loss: 2.0693 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00024: val_loss improved from 2.11186 to 2.06931, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.5497 - accuracy: 0.7500 - val_loss: 2.0629 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00025: val_loss improved from 2.06931 to 2.06289, saving model to /content/gdrive/My Drive/saved models/vgg16_model.h5\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2585 - accuracy: 0.9062 - val_loss: 2.1003 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 2.06289\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3310 - accuracy: 0.8125 - val_loss: 2.1406 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 2.06289\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2802 - accuracy: 0.8125 - val_loss: 2.1640 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 2.06289\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3331 - accuracy: 0.9375 - val_loss: 2.1941 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 2.06289\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.6113 - accuracy: 0.8125 - val_loss: 2.2048 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 2.06289\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2103 - accuracy: 0.8750 - val_loss: 2.2065 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 2.06289\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2234 - accuracy: 0.8750 - val_loss: 2.1987 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 2.06289\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4877 - accuracy: 0.8750 - val_loss: 2.2009 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 2.06289\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4909 - accuracy: 0.8125 - val_loss: 2.2113 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 2.06289\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1963 - accuracy: 0.8750 - val_loss: 2.2276 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 2.06289\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.7539 - accuracy: 0.9062 - val_loss: 2.2183 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 2.06289\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1805 - accuracy: 0.9375 - val_loss: 2.1986 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 2.06289\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3253 - accuracy: 0.8750 - val_loss: 2.1869 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 2.06289\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3236 - accuracy: 0.8750 - val_loss: 2.1668 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 2.06289\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2973 - accuracy: 0.9375 - val_loss: 2.1481 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 2.06289\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3693 - accuracy: 0.8438 - val_loss: 2.1355 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 2.06289\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2974 - accuracy: 0.9062 - val_loss: 2.1361 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 2.06289\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4031 - accuracy: 0.9062 - val_loss: 2.1408 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 2.06289\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1540 - accuracy: 0.9375 - val_loss: 2.1521 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 2.06289\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4689 - accuracy: 0.8438 - val_loss: 2.1745 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 2.06289\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4832 - accuracy: 0.8750 - val_loss: 2.1889 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 2.06289\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0870 - accuracy: 0.9375 - val_loss: 2.1949 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 2.06289\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3514 - accuracy: 0.9062 - val_loss: 2.1924 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 2.06289\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1587 - accuracy: 0.9688 - val_loss: 2.1905 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 2.06289\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2134 - accuracy: 0.8750 - val_loss: 2.1869 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 2.06289\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.1847 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 2.06289\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2511 - accuracy: 0.9062 - val_loss: 2.1793 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 2.06289\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2007 - accuracy: 0.9062 - val_loss: 2.1783 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 2.06289\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3561 - accuracy: 0.9062 - val_loss: 2.1770 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 2.06289\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2246 - accuracy: 0.9062 - val_loss: 2.1751 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 2.06289\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3056 - accuracy: 0.9062 - val_loss: 2.1714 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 2.06289\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2765 - accuracy: 0.8750 - val_loss: 2.1648 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 2.06289\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1545 - accuracy: 0.9375 - val_loss: 2.1615 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 2.06289\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3523 - accuracy: 0.8438 - val_loss: 2.1583 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 2.06289\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3884 - accuracy: 0.8750 - val_loss: 2.1568 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 2.06289\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2420 - accuracy: 0.8750 - val_loss: 2.1554 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 2.06289\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0964 - accuracy: 0.9688 - val_loss: 2.1536 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 2.06289\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2865 - accuracy: 0.9062 - val_loss: 2.1516 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 2.06289\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3057 - accuracy: 0.9062 - val_loss: 2.1505 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 2.06289\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1903 - accuracy: 0.9062 - val_loss: 2.1505 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 2.06289\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.5907 - accuracy: 0.7812 - val_loss: 2.1507 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 2.06289\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 2.1510 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 2.06289\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0794 - accuracy: 0.9688 - val_loss: 2.1511 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 2.06289\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3109 - accuracy: 0.9062 - val_loss: 2.1520 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 2.06289\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4134 - accuracy: 0.8750 - val_loss: 2.1519 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 2.06289\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3205 - accuracy: 0.8438 - val_loss: 2.1524 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 2.06289\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3090 - accuracy: 0.8750 - val_loss: 2.1531 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 2.06289\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2724 - accuracy: 0.8438 - val_loss: 2.1531 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 2.06289\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1239 - accuracy: 0.9375 - val_loss: 2.1531 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 2.06289\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 2.1529 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 2.06289\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3986 - accuracy: 0.9375 - val_loss: 2.1525 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 2.06289\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1881 - accuracy: 0.8750 - val_loss: 2.1524 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 2.06289\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3566 - accuracy: 0.8750 - val_loss: 2.1518 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 2.06289\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2550 - accuracy: 0.9062 - val_loss: 2.1515 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 2.06289\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3203 - accuracy: 0.8750 - val_loss: 2.1515 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 2.06289\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1925 - accuracy: 0.9375 - val_loss: 2.1515 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 2.06289\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2473 - accuracy: 0.9375 - val_loss: 2.1515 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 2.06289\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1558 - accuracy: 0.9375 - val_loss: 2.1516 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 2.06289\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4852 - accuracy: 0.8438 - val_loss: 2.1518 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 2.06289\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2688 - accuracy: 0.9375 - val_loss: 2.1520 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 2.06289\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1684 - accuracy: 0.9375 - val_loss: 2.1524 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 2.06289\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.5728 - accuracy: 0.7812 - val_loss: 2.1528 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 2.06289\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3092 - accuracy: 0.9062 - val_loss: 2.1529 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 2.06289\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4843 - accuracy: 0.8750 - val_loss: 2.1531 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 2.06289\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 2.1534 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 2.06289\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4642 - accuracy: 0.8750 - val_loss: 2.1537 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 2.06289\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3512 - accuracy: 0.8750 - val_loss: 2.1540 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 2.06289\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1364 - accuracy: 0.9375 - val_loss: 2.1544 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 2.06289\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3247 - accuracy: 0.8438 - val_loss: 2.1546 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 2.06289\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1895 - accuracy: 0.9688 - val_loss: 2.1548 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 2.06289\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.5831 - accuracy: 0.8125 - val_loss: 2.1550 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 2.06289\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1901 - accuracy: 0.8750 - val_loss: 2.1551 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 2.06289\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.5746 - accuracy: 0.8125 - val_loss: 2.1553 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 2.06289\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1210 - accuracy: 0.9688 - val_loss: 2.1554 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 2.06289\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2260 - accuracy: 0.9062 - val_loss: 2.1556 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 2.06289\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2973 - accuracy: 0.9375 - val_loss: 2.1557 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 2.06289\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 2.1558 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 2.06289\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2673 - accuracy: 0.8750 - val_loss: 2.1559 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 2.06289\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4580 - accuracy: 0.7188 - val_loss: 2.1560 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 2.06289\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1170 - accuracy: 0.9375 - val_loss: 2.1561 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 2.06289\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4931 - accuracy: 0.9062 - val_loss: 2.1561 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 2.06289\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.4747 - accuracy: 0.9375 - val_loss: 2.1561 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 2.06289\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0831 - accuracy: 0.9688 - val_loss: 2.1561 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 2.06289\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1209 - accuracy: 0.9688 - val_loss: 2.1561 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 2.06289\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3256 - accuracy: 0.8750 - val_loss: 2.1561 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 2.06289\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4747 - accuracy: 0.8125 - val_loss: 2.1562 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 2.06289\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1398 - accuracy: 0.9375 - val_loss: 2.1562 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 2.06289\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2012 - accuracy: 0.9062 - val_loss: 2.1562 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 2.06289\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2717 - accuracy: 0.8750 - val_loss: 2.1562 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 2.06289\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2803 - accuracy: 0.8438 - val_loss: 2.1563 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 2.06289\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1961 - accuracy: 0.9375 - val_loss: 2.1563 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 2.06289\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3086 - accuracy: 0.9062 - val_loss: 2.1563 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 2.06289\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3619 - accuracy: 0.8750 - val_loss: 2.1563 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 2.06289\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4526 - accuracy: 0.9062 - val_loss: 2.1563 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 2.06289\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3073 - accuracy: 0.9375 - val_loss: 2.1563 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 2.06289\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1643 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 2.06289\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3673 - accuracy: 0.8125 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 2.06289\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3108 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 2.06289\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3043 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 2.06289\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 2.06289\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3468 - accuracy: 0.7812 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 2.06289\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2964 - accuracy: 0.8125 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 2.06289\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1619 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 2.06289\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4658 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 2.06289\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1525 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 2.06289\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.3551 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 2.06289\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1389 - accuracy: 1.0000 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 2.06289\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3603 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 2.06289\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3296 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 2.06289\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4083 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 2.06289\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2788 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 2.06289\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 2.06289\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3048 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 2.06289\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2406 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 2.06289\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2144 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 2.06289\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1609 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 2.06289\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1148 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 2.06289\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1627 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 2.06289\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2088 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 2.06289\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1337 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 2.06289\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3883 - accuracy: 0.8125 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 2.06289\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 2.06289\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1289 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 2.06289\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2763 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 2.06289\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4100 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 2.06289\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1626 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 2.06289\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 2.06289\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1204 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 2.06289\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2488 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 2.06289\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2669 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 2.06289\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1571 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 2.06289\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2616 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 2.06289\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2993 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 2.06289\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2062 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 2.06289\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1541 - accuracy: 1.0000 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 2.06289\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.0884 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 2.06289\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2945 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 2.06289\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4861 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 2.06289\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2803 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 2.06289\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3406 - accuracy: 0.8125 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 2.06289\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4234 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 2.06289\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1782 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 2.06289\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3214 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 2.06289\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4540 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 2.06289\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1554 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 2.06289\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3731 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 2.06289\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.7553 - accuracy: 0.7812 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 2.06289\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2737 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 2.06289\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4991 - accuracy: 0.8125 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 2.06289\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1204 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 2.06289\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1879 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 2.06289\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1952 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 2.06289\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1851 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 2.06289\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3196 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 2.06289\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3787 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 2.06289\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2054 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 2.06289\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1705 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 2.06289\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1473 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 2.06289\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2118 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 2.06289\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3909 - accuracy: 0.8125 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 2.06289\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4293 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 2.06289\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2540 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 2.06289\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.1830 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 2.06289\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2619 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 2.06289\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4618 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 2.06289\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2020 - accuracy: 0.9062 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 2.06289\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3359 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 2.06289\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 7s 4s/step - loss: 0.2865 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 2.06289\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4345 - accuracy: 0.8438 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 2.06289\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1630 - accuracy: 0.9375 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 2.06289\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4056 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 2.06289\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2772 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 2.06289\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.4391 - accuracy: 0.8125 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 2.06289\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.3298 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 2.06289\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.2402 - accuracy: 0.8750 - val_loss: 2.1564 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 2.06289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er4QLDe1A9Gw",
        "colab_type": "code",
        "outputId": "bbb894e3-7054-4397-a8e7-a5565fed325e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(history.epoch,history.history['val_loss'],'-o',label='validation')\n",
        "plt.plot(history.epoch,history.history['loss'],'-o',label='training')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.title('Loss vs Epochs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss vs Epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsqsDUJiDMUQ",
        "colab_type": "code",
        "outputId": "55aaf69a-1b52-4007-d16c-048755fb084d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(history.epoch, history.history['lr'],'-o')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title('Learning Rate vs Epochs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Learning Rate vs Epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzoVgZ9DDZk3",
        "colab_type": "code",
        "outputId": "019e829c-9cd5-4657-88fd-cb657b655340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "\n",
        "plt.plot(history.epoch,history.history['val_accuracy'], '-o', label='validation')\n",
        "plt.plot(history.epoch,history.history['accuracy'], '-o', label='training')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Epochs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy vs Epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXcWOzzYEZxP",
        "colab_type": "code",
        "outputId": "60b31ae4-d709-49cb-fcf3-c9a98c32d997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "for i in history.history:\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val_loss\n",
            "val_accuracy\n",
            "loss\n",
            "accuracy\n",
            "lr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYaDSJw-D5FE",
        "colab_type": "code",
        "outputId": "9265e313-3058-478d-e12a-6f84c57e02a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/ImagesPred/Images/Test/Dipika/IMG20180110082005.jpg', target_size = (Image_Size, Image_Size))\n",
        "#test_image = image.load_img('/content/ImagesPred/Images/Test/Shiv/IMG20200102162934.jpg', target_size = (Image_Size, Image_Size))\n",
        "#test_image = image.load_img('/content/ImagesPred/Images/Test/Siddhant/IMG20191015153026.jpg', target_size = (Image_Size, Image_Size))\n",
        "#test_image = image.load_img('/content/ImagesPred/Images/Test/Turtle/IMG20200418194924_01.jpg', target_size = (Image_Size, Image_Size))\n",
        "\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "train_generator.class_indices\n",
        "result = custom_model.predict(test_image)\n",
        "train_generator.class_indices\n",
        "train_generator.class_indices,result[0][0],result[0][1],result[0][2],result[0][3]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Dipika': 0, 'Shiv': 1, 'Siddhant': 2, 'Turtle': 3}, 1.0, 0.0, 0.0, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMU0WLP7EbfH",
        "colab_type": "code",
        "outputId": "26df9200-f197-49b4-febf-65d10e96164c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if result[0][0] == 1:\n",
        "    prediction = 'Dipika'\n",
        "    print(prediction)\n",
        "elif result[0][1] == 1:\n",
        "    prediction = 'Shiv'\n",
        "    print(prediction)\n",
        "elif result[0][2] == 1:\n",
        "    prediction = 'Siddhant'\n",
        "    print(prediction)\n",
        "elif result[0][3] == 1:\n",
        "    prediction = 'Turtle'\n",
        "    print(prediction)\n",
        "else:\n",
        "    prediction = 'Not able to predict'\n",
        "    print(prediction)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dipika\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziYgJdi7Kfqf",
        "colab_type": "code",
        "outputId": "7fab8cc8-6f31-4334-8044-ebaa2d7dbdf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Below result is run of 50 epoch\n",
        "results = custom_model.evaluate_generator(train_generator, verbose=1)\n",
        "dict(zip(custom_model.metrics_names, results))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 6s 3s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 1.0, 'loss': 0.021319391205906868}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eve9fEqfTWgC",
        "colab_type": "code",
        "outputId": "21624c77-013f-4b7a-9d21-b63ed0ba88ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Below result is run of 50 epoch\n",
        "results = custom_model.evaluate_generator(validation_generator, verbose=1)\n",
        "dict(zip(custom_model.metrics_names, results))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 2s 2s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5, 'loss': 2.1563875675201416}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDkyOerwnGQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}