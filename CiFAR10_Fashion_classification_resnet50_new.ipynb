{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CiFAR10-Fashion_classification_resnet50_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivdutta/AdvanceCNN/blob/master/CiFAR10_Fashion_classification_resnet50_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0elizLx20lPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0206af1d-cef5-43da-9a5a-6ecda4d53c7c"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "#from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSZA2qJJFWiG",
        "colab_type": "code",
        "outputId": "5e1ebc5a-90bf-4aee-9f14-749f038d8840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z8FC5ym440h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2fee07be-8e91-4faa-bf27-5b98d9c4fc62"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "!unzip -q \"/content/gdrive/My Drive/CNN_Images/VGG_class_data.zip\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n",
            "replace data/test/backpack/00000010.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lwOggMN5Jej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c936949b-77dd-49f8-a1e3-b96869d7251e"
      },
      "source": [
        "!ls /content/data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMnLaugWwMgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Give dataset path\n",
        "trainpath = \"/content/data/train\"\n",
        "testpath = \"/content/data/test\"\n",
        "classes = 4\n",
        "Image_Size =128\n",
        "batch_size=20\n",
        "\n",
        "INIT_LR = 1e-4\n",
        "BS = 32\n",
        "NUM_EPOCHS = 20\n",
        "# define the path to the serialized output model after training\n",
        "MODEL_PATH = \"fashion_resnet.model\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWVo7KDc06tH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b24e3dca-a033-40cf-903e-04a55ba358c2"
      },
      "source": [
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bahqztPWYtA2",
        "colab_type": "code",
        "outputId": "ba2bfa5d-f574-45d4-9f34-72798866aa88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "!unzip -q \"/content/gdrive/My Drive/CNN_Images/VGG_class_data.zip\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6oj-8XzY1s1",
        "colab_type": "code",
        "outputId": "c8711fbb-61f1-4acc-d056-40f28b23cbb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls /content/data/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iug2iWNviWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#baseModel.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZPjaoOO8beV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the training training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=25,\n",
        "\tzoom_range=0.1,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\tshear_range=0.2,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)\n",
        "valAug = ImageDataGenerator()\n",
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# the mean subtraction value for each of the data augmentation\n",
        "# objects\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LngUU_lQ8nR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a59bfae2-3652-433a-d13a-8675faf20c10"
      },
      "source": [
        "# initialize the training generator\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "\ttrainpath,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size=BS)\n",
        "# initialize the validation generator\n",
        "valGen = valAug.flow_from_directory(\n",
        "\ttestpath,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)\n",
        "# initialize the testing generator\n",
        "testGen = valAug.flow_from_directory(\n",
        "\ttestpath,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 475 images belonging to 4 classes.\n",
            "Found 264 images belonging to 4 classes.\n",
            "Found 264 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sExkN0NGCpMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2318f4a4-6ccf-428d-ac8c-3675395e12c3"
      },
      "source": [
        "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
        "# off\n",
        "print(\"[INFO] preparing model...\")\n",
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(classes, activation=\"softmax\")(headModel)\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] preparing model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxfWoeMnzVDI",
        "colab_type": "code",
        "outputId": "2b64a641-dc20-4a3c-f44e-d22cd556a525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "# compile the model\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / NUM_EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\tmetrics=[\"accuracy\"])\n",
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=len(list(paths.list_files(trainpath))) // BS,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=len(list(paths.list_files(testpath))) // BS,\n",
        "\tepochs=NUM_EPOCHS)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training model...\n",
            "WARNING:tensorflow:From <ipython-input-27-a5773ce48aea>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.6181 - accuracy: 0.4353 - val_loss: 0.2877 - val_accuracy: 0.7695\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.3124 - accuracy: 0.7088 - val_loss: 0.1471 - val_accuracy: 0.9297\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.1738 - accuracy: 0.8578 - val_loss: 0.0939 - val_accuracy: 0.9609\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.1113 - accuracy: 0.9165 - val_loss: 0.0717 - val_accuracy: 0.9609\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.0918 - accuracy: 0.9278 - val_loss: 0.0657 - val_accuracy: 0.9648\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0892 - accuracy: 0.9300 - val_loss: 0.0530 - val_accuracy: 0.9648\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.0620 - accuracy: 0.9526 - val_loss: 0.0494 - val_accuracy: 0.9688\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.0586 - accuracy: 0.9616 - val_loss: 0.0546 - val_accuracy: 0.9688\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0518 - accuracy: 0.9594 - val_loss: 0.0422 - val_accuracy: 0.9727\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0570 - accuracy: 0.9571 - val_loss: 0.0447 - val_accuracy: 0.9688\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0414 - accuracy: 0.9684 - val_loss: 0.0406 - val_accuracy: 0.9727\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.0328 - accuracy: 0.9819 - val_loss: 0.0443 - val_accuracy: 0.9688\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.0419 - accuracy: 0.9661 - val_loss: 0.0422 - val_accuracy: 0.9727\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.0331 - accuracy: 0.9819 - val_loss: 0.0439 - val_accuracy: 0.9766\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.0287 - accuracy: 0.9865 - val_loss: 0.0383 - val_accuracy: 0.9766\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0244 - accuracy: 0.9821 - val_loss: 0.0374 - val_accuracy: 0.9766\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0313 - accuracy: 0.9774 - val_loss: 0.0375 - val_accuracy: 0.9766\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0241 - accuracy: 0.9865 - val_loss: 0.0384 - val_accuracy: 0.9766\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0211 - accuracy: 0.9887 - val_loss: 0.0373 - val_accuracy: 0.9766\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0209 - accuracy: 0.9865 - val_loss: 0.0326 - val_accuracy: 0.9805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIGlTKsD-kSs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "38ea8da5-0b87-4c30-ba6d-ab0907696ecf"
      },
      "source": [
        "# reset the testing generator and then use our trained model to\n",
        "# make predictions on the data\n",
        "print(\"[INFO] evaluating network...\")\n",
        "testGen.reset()\n",
        "predIdxs = model.predict_generator(testGen,\tsteps=(len(list(paths.list_files(testpath))) // BS) + 1)\n",
        "predIdxs"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9991500e-01, 7.9214105e-06, 1.9859346e-05, 5.7301353e-05],\n",
              "       [9.9874395e-01, 4.0965947e-06, 1.9369242e-04, 1.0583905e-03],\n",
              "       [9.9716115e-01, 2.9229256e-04, 1.6245105e-04, 2.3841052e-03],\n",
              "       ...,\n",
              "       [1.2710016e-02, 2.0468456e-03, 3.6163307e-03, 9.8162675e-01],\n",
              "       [5.2102428e-06, 3.7475405e-04, 9.4299985e-06, 9.9961060e-01],\n",
              "       [1.3053449e-05, 1.4790909e-06, 2.7253518e-06, 9.9998271e-01]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqY84TSsAr8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "9b08dfec-6a2c-42f5-d8db-a9338f9ac428"
      },
      "source": [
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "predIdxs"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXn2O-lyA94e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "11cd3dea-8fa4-40ec-ee28-cf27532e9ed2"
      },
      "source": [
        "# show a nicely formatted classification report\n",
        "print(classification_report(testGen.classes, predIdxs,\n",
        "\ttarget_names=testGen.class_indices.keys()))\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving model...\")\n",
        "model.save(MODEL_PATH, save_format=\"h5\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    backpack       0.98      0.98      0.98        66\n",
            "    footwear       0.97      0.98      0.98        66\n",
            "     glasses       1.00      0.95      0.98        66\n",
            "       watch       0.96      0.98      0.97        66\n",
            "\n",
            "    accuracy                           0.98       264\n",
            "   macro avg       0.98      0.98      0.98       264\n",
            "weighted avg       0.98      0.98      0.98       264\n",
            "\n",
            "[INFO] saving model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yum6vkWJ7B7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_loaded = tf.keras.models.load_model(MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a06YvS7e7VcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d3e0fed-1ad4-49b5-b8d7-bb7efc66df70"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpMvzuPYCBsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "26b960f7-ace5-463c-a83d-58d96f063280"
      },
      "source": [
        "!ls /content/data/test/backpack"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00000010.png  00000269.png  00000335.jpg  00000350.jpg\t00000368.jpg\n",
            "00000018.png  00000270.png  00000336.jpg  00000351.jpg\t00000370.png\n",
            "00000027.png  00000275.png  00000337.jpg  00000352.jpg\t00000371.jpg\n",
            "00000053.png  00000324.jpg  00000338.jpg  00000353.jpg\t00000372.jpg\n",
            "00000069.png  00000325.jpg  00000340.jpg  00000354.jpg\t00000374.jpg\n",
            "00000131.png  00000326.jpg  00000341.png  00000355.jpg\t00000375.jpg\n",
            "00000137.png  00000327.jpg  00000342.jpg  00000356.jpg\t00000376.jpg\n",
            "00000198.png  00000328.jpg  00000343.jpg  00000357.jpg\t00000377.jpg\n",
            "00000199.png  00000329.png  00000344.jpg  00000359.jpg\t00000378.jpg\n",
            "00000208.png  00000330.png  00000345.jpg  00000360.jpg\t00000379.jpg\n",
            "00000214.png  00000331.jpg  00000346.jpg  00000361.jpg\n",
            "00000217.png  00000332.jpg  00000347.jpg  00000362.jpg\n",
            "00000245.png  00000333.jpg  00000348.jpg  00000363.jpg\n",
            "00000267.png  00000334.jpg  00000349.jpg  00000366.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU_urfF77yff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "ae6c0586-e473-4e2a-bb8f-5fba4bcbd183"
      },
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage import io\n",
        "\n",
        "input_img= \"/content/data/test/backpack/00000359.jpg\"\n",
        "input_img = io.imread(input_img)\n",
        "input_img = cv2.resize(input_img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n",
        "print('Input Dimensions - Image : ',input_img.shape)\n",
        "cv2_imshow(input_img)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Dimensions - Image :  (128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F241B4A95C0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNDQwJ18Xk_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = input_img\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}